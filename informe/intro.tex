\chapter{{Introducción}}

\section{{Motivación}}

En el contexto de la neuropsicología digital y de la psiquiatría computacional
es común realizar análisis de movimientos oculares de sujetos al ser estos
presentados con distintos estímulos visuales \cite{{munoz_2004_look_away,
clifton_2016_eye_movements_in_reading}}.
Habitualmente este tipo de ensayos se realiza en contextos presenciales de
laboratorio con equipos de seguimiento ocular especializados pero existen
diversos motivos para explorar la utilización de implementaciones abiertas de
\eyetrackers en navegadores web.
El costo de los equipos especializados puede resultar prohibitivo
\cite{{zandi_2021_pupilext}}.
La disparidad entre el costo final de estos equipos y el hardware que los
compone indicaría que gran parte del valor proviene del desarrollo del software
utilizado y de licencias para su uso \cite{{zandi_2021_pupilext,
xu_2015_turker_gaze}}.
Al ser tal software propietario se imposibilita auditar los algoritmos internos
\cite{{zandi_2021_pupilext}}.
Por otro lado, la característica presencial de estos experimentos dificulta la
asistencia de sujetos, ya sea por ejemplo por lejanía geográfica o bien por
eventos de mayor magnitud como puede ser una cuarentena nacional.

Se destaca además la aplicabilidad de estas herramientas al estudio de
usabilidad de interfaces digitales \cite{{papoutsaki_2017_search_gazer}} y a la
educación digital para por ejemplo detectar pérdidas de atención en clases
masivas virtuales \cite{{zhao_2017_mind_wandering}}.
En el campo de la oftalmología han surgido propuestas de utilizar \eyetracking
para la estimación del campo visual
\cite{{leitner_2021_eyetracking_based_visual_field,
murray_2009_children_perimetry_using_eye_tracking}}.
Si bien lo más probable es que estos análisis por sí sólos no sean suficientes
para realizar un diagnóstico sobre condiciones neuropsicológicas, sí tienen
potencial de asistirlo en conjunto de otras medidas
\cite{{clark_2019_eye_tracking_potential_in_ophtalmology}}.

En este contexto han aparecido herramientas que buscan ser alternativas a los
\eyetrackers comerciales habituales.
Entre ellas se remarca \pupilext que busca proveer el software necesario para
un sistema de detección de pupilas.
Quien esté levantando tal sistema no requiere un conocimiento profundo sobre
cómo implementar un \eyetracker: alcanza en cambio con proveer el hardware
necesario, seguir las instrucciones y correr el software provisto
\cite{{zandi_2021_pupilext}}.
Otros trabajos han comenzado a explorar la utilización de las cámaras web
domésticas para proveer estimación de la mirada \cite{{xu_2015_turker_gaze,
papoutsaki_2016_webgazer, huang_2016_pace}}.
La tabla \ref{{tab:implementations}} ilustra algunas implementaciones que han
surgido recientemente.
El correcto uso de estas herramientas podría abrir la puerta a su uso en el
desarrollo de interfaces humano - máquina (HMI) o a la realización de ensayos
clínicos de manera remota y más económica.

Con el presente trabajo se busca explorar la aplicabilidad del \eyetracking
\textit{{online}} al diagnóstico de condiciones neuropsicológicas.
Para ello se evaluarán las implementaciones existentes.
En base a ellas y a desarrollos propios se buscará la construcción de un
prototipo de \eyetracker web.
Se experimentará luego con él para buscar replicar resultados obtenidos en
análisis tradicionales.

\begin{{table}}[htb]
\centering
\tiny
\begin{{tabular}}{{|p{{0.1\linewidth}}|p{{0.15\linewidth}}|p{{0.1\linewidth}}|p{{0.35\linewidth}}|p{{0.3\linewidth}}|}}
    \hline
    trabajo
    & hardware necesario
    & es navegador compatible?
    & calidad reportada (MAE=\textit{{mean average error}}
    & experimentación \\
    \hline
    \hline
    Santini et al, EyeRecToo \cite{{santini_2017_eyerectoo}}, \eyetracking
    montado a la cabeza
    & soporte para tres modelos comerciables montables a la cabeza, aunque
    generalizable
    & no
    & MAE $<$ 1°
    & una instancia de 5 sujetos de los cuales 2 usan anteojos, no se indica
    cómo calculan el valor ni qué experimento realizan
    \\ \hline
    Zandi et al, PupilEXT \cite{{zandi_2021_pupilext}}, populometría
    & una o dos cámaras industriales, un emisor de luz NIR (Near Infra Red)
    & no
    & MAE $\approx$ 0.0059 mm en el diámetro de la pupila, frecuencia alcanzada
    de 120 Hz según el algoritmo de estimación utilizado 
    & no mencionada
    \\ \hline
    Huang et al, PACE \cite{{huang_2016_pace}}, \eyetracking auto calibrante
    & webcam
    & no
    & MAE $\approx$ 2.56°, pero ese valor se alcanza después de 7 iteraciones
    de autocalibración.
    En promedio toma 4 horas alcanzar esa precisión.
    No se menciona la precisión al inicio.
    & 10 sujetos que debían elegir entre 1 de 5 tareas en las cuales hay mucha
    interacción.
    Realizan la tarea hasta alcanzar 1500 interacciones.
    Además realizan mucha experimentación respecto de la correlación entre la
    mirada y distintos tipos de interacción.
    \\ \hline
    Xu et al, TurkerGaze \cite{{xu_2015_turker_gaze}}, \textit{{crowdsourcing}}
    de mapas de saliencia
    & webcam
    & sí
    & MAE $\approx$ 1.06° respecto de 33 puntos estáticos en la pantalla.
    MAE $\approx$ 1.32° respecto de \eyetracker comercial.
    Los mapas de saliencia resultantes tienen sesgo hacia el centro que no
    debería estar.
    & Los puntos estáticos son mostrados por 1,5 s, usando los últimos 0,5 para
    tomar la medida.
    Al comprar con el \eyetracker comercial utilizan sus predicciones como
    \textit{{ground truth}}.
    No se aclara como es la intercalación entre tareas y calibraciones.
    \\ \hline
    Papoutsaki et al, WebGazer \cite{{papoutsaki_2016_webgazer}}, \eyetracking
    auto calibrante
    & webcam
    & sí
    & MAE entre 150 px y 250 px
    & una instancia online con 82 sujetos y otra instancia presencial con 5 en
    las cuales debían llenar un \textit{{múltiple choice}} de 40
    \textit{{yes/no questions}}.
    En la instancia presencial comparan contra un eye tracker comercial pero en
    la online no queda claro qué se usa de ground truth.
    \\ \hline
\end{{tabular}}
Las distintas propuestas comparten el deseo de proveer software para que luego
quien lo utilice tenga que a lo sumo proveer hardware.
Se diferencian según el problema que buscan solucionar (e.g., pupilometría,
\eyetracking montado a la cabeza) y en los requerimientos impuestos de
hardware.

TODO: Cómo presento esta tabla? Si no le achico la letra o bien se va del
margen o bien quedan muy pocas palabras por columna

\caption{{Implementaciones abiertas basadas en \eyetracking}}
\label{{tab:implementations}}
\end{{table}}

\section{{Eye tracking web remoto}}

Los ojos tienen un rol central en la expresión de estados emocionales y
procesos cognitivos que una persona está atravesando.
A la par del estudio de la cara, el estudio de los ojos permite tanto su
localización en imágenes como una posterior estimación del comportamiento de un
individuo.
En varias tareas de visión es entonces central su estudio incluso cuando no son
el eje del análisis (e.g., detección de caras
\cite{{hansen_2009_eye_of_the_beholder}}).
La mirada es un reflejo del foco de atención del pensamiento, por lo que su
análisis está también por ejemplo ligado a la teoría de la lectura
\cite{{just_1980_theory_of_reading}}.

De entre estas tareas se destaca la estimación de la mirada de un sujeto en una
pantalla.
En este trabajo se la explora aplicada al diagnóstico de condiciones
neuropsicológicas en un contexto web remoto, el cual implica diferencias
respecto del contexto habitual de laboratorio.
En primer lugar, nuestro hardware se limitará a una única cámara web sin la
posibilidad de agregar otras cámaras o emisores de luz.
En segundo lugar, tampoco se tendrá control directo sobre el entorno.
La iluminación podría, por ejemplo, ser variable durante el experimento.
Finalmente, se destaca la ausencia de un técnico que supervise el experimento.
A continuación se describen distintos aspectos relacionados al \eyetracking web.

\subsection{{Costos del \eyetracking}}

En contextos habituales de laboratorio, la utilización de \eyetracking en
experimentos cognitivos puede resultar prohibitiva debido a sus costos.
El hardware industrial utilizado suele representar solamente una fracción del
costo.
El valor agregado por el software utilizado y por las licencias suele en cambio
ser lo que más pesa.
Asimismo, la realización de experimentos presenciales puede implicar costos
propios \cite{{zandi_2021_pupilext, xu_2015_turker_gaze}}.

El software de \eyetrackers comerciales suele estar documentado aunque será
también en general propietario.
Esto último previene una auditoría directa de los algoritmos internos.
Al mismo tiempo, por más que han surgido propuestas
\cite{{antoniades_2013_standarized_protocol}}, no se siguen estándares de
reportes de calidad de las estimaciones.
En parte por estas razones la comparación de conclusiones de distintos trabajos
se ve dificultada \cite{{zandi_2021_pupilext,
salvucci_2000_identifying_fixations}}.

En base a estos problemas, en los últimos años ha habido creciente interés en
implementaciones abiertas de \eyetrackers.
Esto vale tanto para el \eyetracking web \cite{{xu_2015_turker_gaze,
papoutsaki_2016_webgazer}} como para \eyetracking montado a la cabeza
\cite{{santini_2017_eyerectoo}} y \eyetracking tradicional de laboratorio
\cite{{zandi_2021_pupilext}}.
El punto común a las distintas implementaciones es la búsqueda de aprovechar
hardware existente (e.g., cámaras web) o de que por lo menos el técnico pueda
proveer su propio equipo (i.e., adquirir cámaras industriales por una fracción
del costo de \eyetrackers comerciales y encargarse uno mismo de levantar el
sistema).
El \eyetracking web tiene la particularidad de ser distribuible a través de
navegadores web, lo que elimina la necesidad de que los sujetos asistan
presencialmente a la realización de experimentos.
Se facilita además la compatibilidad con múltiples sistemas operativos.

\subsection{{Contexto web}}

No exploramos todas las opciones de \eyetracking en base a cámaras web, si no
que nos restringimos en particular a aquellas que además sean capaces de correr
en un navegador web.
Esto se debe a dos razones:
a) facilidad en la distribución de experimentos,
b) compatibilidad con \jspsych.
\jspsych es un \textit{{framework}} web escrito en \js orientado a asistir a la
implementación de experimentos cognitivos \cite{{joshua_2015_jspsych}}.
Formaliza una estructura para construir experimentos, proveyendo utilidades
para tareas comunes como mostrar un texto en la pantalla y esperar a una
respuesta en el teclado por parte del sujeto.
Además, la comunidad puede extender la herramienta a través de la
implementación de sus propios \textit{{plugins}}, como \psychophysics
\cite{{kuroki_2021_psycho_physics}} o \virtualchinrest
\cite{{li_2020_virtual_chinrest}}.
\jspsych ejemplifica cómo la creciente sofisticación de tecnologías web alienta
la construcción de herramientas utilizables en navegadores.

\subsection{{Inicialización}}

En laboratorios los sujetos pueden ser asistidos por un técnico o
experimentador al momento de iniciar la experimentación.
Pueden además realizarse ajustes y calibraciones comunes a todos los sujetos
\cite{{hansen_2009_eye_of_the_beholder}}, y son todos registrados en las mismas
condiciones.
En un contexto remoto en cambio estaremos sujetos a factores no controlables
como luz o hardware variables.
Al no contar con un técnico que dé instrucciones, recae en el sujeto
posicionarse correctamente respecto de la cámara web.

Debido a estas diferencias de contextos, al iniciar una sesión es beneficioso
verificar las condiciones del entorno, solicitar al sujeto que realice ajustes
e imponiendo incluso restricciones para la realización del experimento.
\turkergaze \cite{{xu_2015_turker_gaze}} calcula la intensidad de la luz al
momento de iniciar, solicitando al sujeto que la ajuste si fuera necesario.
Se verifica además que se alcance una resolución mínima de la cámara web y un
valor mínimo de cuadros por segundo (\textit{{frames per second}},
\textit{{FPS}}) una vez que la herramienta está en funcionamiento.
Estima también ciertos parámetros de la posición de la cabeza para asegurarse
que esta esté alineada con la cámara web al inicio del experimento.
\webgazer requiere al sujeto que posicione su cabeza dentro de un recuadro
\cite{{papoutsaki_2016_webgazer}}.

\subsection{{Modelado de la mirada}}

Si bien continúa siendo un problema desafiante, existe amplia investigación y
variedad de modelos cuyo objetivo final sea estimar dónde mira un sujeto
\cite{{hansen_2009_eye_of_the_beholder}}.
Estos difieren en sus requerimientos de hardware, en el enfoque de modelado y
en las propiedades que logran garantizar.

Previo a estimar la mirada de un sujeto será necesario localizar sus ojos en
una imagen.
Al ser esto último útil por sí sólo, se lo distingue como un problema aparte al
de estimación de la mirada \cite{{hansen_2009_eye_of_the_beholder}}.
Para resolver esto en el contexto de \eyetracking web una opción es utilizar
modelos de \textit{{facemesh}}, también llamados modelos de \textit{{face
landmarks}} \cite{{papoutsaki_2016_webgazer}}.
Estos modelos construyen una red de puntos clave (\textit{{keypoints}}) que dan
información sobre la estructura de la cara en una imagen.
Utilizando este tipo de modelo pueden luego implementarse heurísticas para
localizar la posición de los ojos (c.f. figura \ref{{fig:facemesh_keypoints}}).

\begin{{figure}}
    \centering
    \includegraphics[width=0.7\linewidth]{{media/facemesh_kepyoints.jpg}}
    \caption{{
        Mapa de \textit{{keypoints}}
        (fuente: documentación de \texttt{{TensorFlowJS}}\protect\footnotemark)
    }}
    La documentación del \textit{{facemesh}} indica cómo acceder a cada uno de
    sus \textit{{keypoint}}.
    De esta manera se pueden extraer elementos que sean de interés (e.g., el
    recuadro de cada ojo) y construir algoritmos que usen tal información.
    \label{{fig:facemesh_keypoints}}
\end{{figure}}
\footnotetext{{\url{{https://github.com/tensorflow/tfjs-models/blob/master/face-landmarks-detection/mesh_map.jpg}}}}

Localizados los ojos se procederá a estimar la mirada del sujeto.
Los métodos para esto son múltiples y categorizables de distintas maneras según
sus características.
En particular nos concentraremos en si se utiliza un modelado explícito de la
estructura de los ojos o si en cambio se utiliza un enfoque basado en
apariencia \cite{{hansen_2009_eye_of_the_beholder}}.
Si bien estas dos categorías no son excluyentes, sí facilitan entender qué
métodos aplican a nuestro caso de uso.

El modelado explícito de los ojos suele basarse en reflejos causados por
emisores externos de luz.
Cuando la luz de estos atraviesa la lente del ojo y la córnea, se generan
reflejos llamados imágenes de Purkinje (c.f. figura
\ref{{fig:purkinje_images}}).
El primero de estos suele denominarse \textit{{glint}}.
A través de este es posible estimar el \textit{{visual axis}} (vector entre el
centro del cristalino y el centro de la fóvea) y el \textit{{optical axis}}
(vector entre el centro del cristalino y el centro de la retina) (c.f. figura
\ref{{fig:optical_visual_axis}}), ambos pudiendo ser utilizados como el vector
correspondiente a la mirada \cite{{hansen_2009_eye_of_the_beholder}}.

\begin{{figure}}
    \centering
    \includesvg{{media/four_Purkinje_images.svg}}
    \caption{{Reflejos de Purkinje (fuente: Wikipedia\protect\footnotemark)}}
    A medida que un rayo de luz atraviesa las distintas estructuras del ojo
    aparecen múltiples puntos de refracción desde los cuales ocurren reflejos
    de luz.
    P1, P2, P3 y P4 corresponden a los cuatro reflejos de Purkinje.
    De entre estos el primero (P1) es aquel que se denomina \textit{{glint}} y
    es utilizado en la estimación de la mirada al realizar un modelado
    explícito de la visión.
    \label{{fig:purkinje_images}}
\end{{figure}}
\footnotetext{{\url{{https://commons.wikimedia.org/wiki/File:Diagram_of_four_Purkinje_images.svg}}}}

\begin{{figure}}
    \centering

    \includegraphics[width=\linewidth]{{media/optical_visual_axis.png}}

    El eje óptico y el eje visual se definen como los ejes entre el centro del
    cristalino y respectivamente el centro de la retina y el centro de la fóvea.
    Estos son comúnmente utilizados como estimación del vector de la mirada.

    TODO: Tendría sentido juntar las dos figuras de los ojos en una misma
    figura que sumarice la estructura del ojo?

    \caption{{Ejes óptico y visual (fuente: Wikipedia\protect\footnotemark,
    modificada)}}
    \label{{fig:optical_visual_axis}}
\end{{figure}}
\footnotetext{{\url{{https://commons.wikimedia.org/wiki/File:Three_Main_Layers_of_the_Eye.png}}}}

En nuestro contexto no es sin embargo posible el agregado de emisores de luz,
por lo que la generación de \textit{{glints}} no es posible.
En consecuencia se descarta el modelado explícito de la mirada.
El modelado por apariencia consiste en cambio en tratar los \textit{{frames}}
como imágenes genéricas aplicando luego técnicas tradicionales de métodos
numéricos (e.g., regresión) para obtener un mapa entre el dominio de estas
imágenes y las coordenadas de la pantalla.
\turkergaze \cite{{xu_2015_turker_gaze}} y luego \webgazer
\cite{{papoutsaki_2016_webgazer}} ilustran una implementación de este tipo de
modelos.
Para ello luego de localizar los ojos, transforman su recuadro de la imagen en
vectores de 120 dimensiones con los cuales se alimenta un modelo de regresión
\textit{{ridge}}.
Así, dado un \textit{{frame}} de la webcam, la salida del modelo será la
coordenada de la pantalla que se está miranddo.
\pace \cite{{huang_2016_pace}} utiliza un mecanismo híbrido en el cual a las
imágenes de los ojos se agregan variables estimadas de la posición de la cabeza
(orientación, rotación y apertura de los ojos).

Del modelado por apariencia se destaca su habilidad en capturar información de
manera implícita.
No serán por ejemplo necesarias calibraciones propias a las cámaras utilizadas
o las individualidades de los sujetos.
Estos modelos tendrían mayor facilidad en lidiar con uso de anteojos
\cite{{hansen_2009_eye_of_the_beholder}}.

Para suavizar las señales que se obtienen de la cámara web y de los modelos
puede utilizarse un filtro Kalman \cite{{welch_1995_kalman_filter}}.
\turkergaze lo utiliza para suavizar los \textit{{keypoints}} del
\textit{{facemesh}} relevantes a su implementación, mientras que \webgazer lo
utiliza para suavizar las estimaciones que va generando.

\subsection{{Invarianza frente a movimientos de cabeza}}

La invarianza de un modelo frente a movimientos de cabeza es su capacidad en
seguir realizando estimaciones correctas a pesar de que el sujeto realice
movimientos.
Restringir el movimiento de los sujetos puede ayudar a lidiar con ello.
La utilización de múltiples cámaras y emisores de luz permitiría la
construcción de \eyetrackers que permitan movimiento libre por parte del
sujeto.
Sin embargo, no se han reportado modelos basados en apariencia que cumplan tal
propiedad.
Para el caso de una única cámara ocurriría en particular que múltiples
posiciones de la cabeza y direcciones de mirada tendrían el mismo aspecto en
las imágenes resultantes \cite{{hansen_2009_eye_of_the_beholder}}.

Para reducir el impacto de movimientos de cabeza, ciertos trabajos de
\eyetracking web \cite{{papoutsaki_2016_webgazer, huang_2016_pace}} exploran la
captura de datos de calibración a través de las interacciones (e.g., clicks)
que el sujeto realice.
Estos trabajos no aplican a nuestro caso de uso pues no podemos garantizar que
el usuario vaya a tener que interactuar con el navegador durante las tareas que
le serán presentadas.

\subsection{{Calibración, validación y descalibración}}
\label{{section:intro:calibration}}

Cualquier sistema de \eyetracking tendrá que ser calibrado previo a su uso.
La complejidad de la calibración a realizar en cada sesión está ligada al
mecanismo de modelado utilizado y al conocimiento que se tenga del entorno.
Conocer el posicionamiento relativo entre el hardware permite por ejemplo
reducir la cantidad de puntos que cada sujeto tendrá que mirar
\cite{{hansen_2009_eye_of_the_beholder}}.
Nuestro contexto de una única cámara y modelado por apariencia es aquel con
menor información del entorno, por lo que su calibración podrá implicar varias
decenas de puntos obtenidos en fases explícitas de calibración
\cite{{xu_2015_turker_gaze}}.

Para nuestro caso de uso es necesaria una fase explícita de calibración.
No se encontró un protocolo que indique cómo llevarla adelante.
Para la implementación de una calibración se necesita definir la cantidad de
estímulos a mostrar así como la disposición con la cual serán presentados.
Debe también decidirse si cada estímulo será mostrado una cantidad fija de
tiempo o si será mostrado hasta que el sujeto interactúe con el sistema (e.g.,
a través de un click en el estímulo presentado).
En base a esto debe luego definirse tanto qué \textit{{frames}} se utilizarán
para calibrar el sistema así como a qué coordenada serán asociado cada
\textit{{frame}} seleccionado.
Ya sea si para cada estímulo se elige un único \textit{{frame}}
\cite{{papoutsaki_2016_webgazer}} o bien una serie de \textit{{frames}}
\cite{{xu_2015_turker_gaze}}, idealmente deberían elegirse aquellos para los
cuales se tiene certeza de que el sujeto está fijando la mirada en el estímulo
presentado.
No es evidente cómo realizar tal selección.
Si se eligieran \textit{{frames}} cercanos al inicio de la aparición del
estímulo podría ocurrir que el sujeto no haya todavía fijado la mirada en él.
Podría también ocurrir que el sujeto pestañee o que simplemente no mire el
estimulo presentado.
Para distintas categorías de interacciones en una interfaz (arrastrar el
puntero, escribir un texto, realizar clicks, etc.) se esperan además distintos
instantes de mayor correspondencia entre la mirada y la posición en la pantalla
de la interacción \cite{{huang_2016_pace}}.
Como ilustrarán dificultades que tuvimos en este trabajo, es también importante
minimizar el tiempo necesario para calibrar el sistema.
Debe entonces maximizarse la calidad de los datos capturados para cada estímulo
presentado, así como minimizarse la cantidad total de estímulos.

Finalizada la calibración es común realizar una validación de las estimaciones
para decidir si debe correrse nuevamente la fase de calibración.
Surgen aquí interrogantes similares a la fase de calibración.
Para que la validación resulte menos tediosa se puede recurrir a su
\textit{{gamification}} \cite{{xu_2015_turker_gaze}}.
Debe además definirse qué validar.
Para nuestro caso de estudio alcanzará con qué las estimaciones permitan
distinguir cuando el sujeto mira a la izquierda, al centro o a la derecha.
Esto depende sin embargo del problema que se esté atacando.
Debe también definirse qué tan exigente ser con tal validación.
Sin suficiente exigencia puede ocurrir luego que las estimaciones no tengan
suficiente calidad para ser analizadas.
Por otro lado, fases demasiado largas podrían resultar tediosas al sujeto
aumentando las chances de que este pierda el interés y abandone el experimento.
El tedio y el aspecto invasivo asociado a las calibraciones explica el interés
en calibrar en base a interacciones por parte del sujeto.

Realizadas la calibración y la validación, puede proseguirse a estimar la
mirada del sujeto.
A diferencia de un contexto de laboratorio, en un contexto web no se cuenta
con invarianza frente a movimientos de cabeza ni con estructuras que limiten el
movimiento del sujeto.
En consecuencia ocurrirá tarde o temprano una descalibración del sistema.
Esta tendrá que ser detectada para luego indicar la necesidad de realizar una
recalibración.
Xu et al \cite{{xu_2015_turker_gaze}} optaron por realizar tareas cortas y
calibrar repetidamente.
La opción explorada en este trabajo consiste en detectar continuamente
movimientos que el sujeto realice con la cabeza.
La necesidad de detectar descalibraciones no parece ser de igual relevancia en
el contexto habitual de laboratorio, pues los modelos de estimación de la
mirada no suelen incluir un mecanismos que indique cuándo el sistema ha pasado
a estar descalibrado \cite{{hansen_2009_eye_of_the_beholder}}.

\section{{Caso de estudio: Tarea de antisacadas}}

En la tarea de antisacadas se indica a los sujetos fijar la mirada un estímulo
central y mirar luego al lado contrario al cual aparece un estímulo lateral.
Se define en paralelo la tarea de prosacada como aquella en la cual el sujeto
debe mirar hacia el mismo lado en el que aparece el estímulo lateral.
Si bien fue propuesta en 1978, cobró notoriedad a partir de 1985 cuando se
demostró que pacientes con lesiones en el lóbulo frontal producían una mayor
cantidad de errores \cite{{smyrnis_2002_big_sample}}.
Desde entonces han aparecido numerosos estudios que buscan establecer
relaciones entre resultados obtenidos, procesos cognitivos implicados y
condición neuropsicológica de los sujetos \cite{{munoz_2004_look_away,
unsworth_2011_distribution_analysis, olincy_1997_age_diminishes_performance,
smyrnis_2002_big_sample, unsworth_2021_working_memory_capacity,
plomecka_2020_retest_reliability}}.
La tabla \ref{{tab:antisaccades}} resume distintos aspectos del diseño y de los
resultados reportados por distintos trabajos.

Esta tarea puede verse como un caso especial de tareas de compatibilidad de
mapeo estímulo-respuesta \cite{{munoz_2004_look_away}} donde las prosacadas
representan el mapeo congruente y las antisacadas representan el mapeo
incongruente.
Como tal, los resultados son en general compatibles con la noción de que los
casos congruentes tendrán menores tiempos de respuesta y menor tasa de error
que aquellos incongruentes.
Los resultados concretos de los experimentos están fuertemente ligados al
diseño de la tarea.
Sin embargo, como noción general puede esperarse una precisión mayor a 0.9 para
las prosacadas y de entre 0.6 y 0.7 para las antisacadas.
Los tiempos de respuesta de ambas tareas estarán situados en el rango [280 ms,
800 ms] siendo consistente dentro de un mismo experimento que las tareas de
antisacadas obtendrán tiempos de respuesta promedio significativamente mayores
que aquellos de las tareas de prosacada.

Esta tarea permite estudiar múltiples procesos cognitivos.
Estos están en particular relacionados al control inhibitorio, el cual está
menos desarrollado en niños (obtienen peor \textit{{performance}} que sujetos
neurotípicos adultos \cite{{munoz_2004_look_away, smyrnis_2002_big_sample}}) y
se ve luego afectado por el envejecimiento
\cite{{olincy_1997_age_diminishes_performance}}.
En efecto, puede medirse la capacidad de los sujetos de inhibir una respuesta
reflexiva (puntualmente el \textit{{visual grasp reflex}}
\cite{{munoz_2004_look_away}}) para en cambio generar una respuesta voluntaria
en la dirección contraria.
Para las antisacadas correctas puede medirse si la distancia de la sacada
coincide con la distancia a la cual apareció el estímulo lateral, lo que daría
indicios sobre la memoria visual espacial
\cite{{olincy_1997_age_diminishes_performance}}.
Rápidas sucesiones de repeticiones de la tarea permiten estudiar la capacidad
de los sujetos de mantenerse atentos al objetivo planteado
\cite{{olincy_1997_age_diminishes_performance}}, lo cual a su vez permite
categorizar los procesos entre \textit{{competition resolution}} (i.e., la
competencia entre el proceso de respuesta reflexiva y el proceso de inhibir tal
respuesta para generar una sacada en la dirección contraria) y \textit{{goal
maintenance}} (i.e., la capacidad de recordar y mantener activado el objetivo).
De manera más general, la tarea permite estudiar la \textit{{working memory
capacity}} \cite{{unsworth_2011_distribution_analysis,
unsworth_2021_working_memory_capacity}} de los sujetos.
Es tangencialmente destacable cómo la práctica de la tarea mejora la
\textit{{performance}} sobre ella al punto de que casos congruentes e
incongruentes obtendrán los mismos resultados
\cite{{unsworth_2011_distribution_analysis}}.

El diseño de la tarea impacta en qué procesos cognitivos son resaltados.
Por ejemplo, la capacidad de recordar el objetivo está influenciada por a) si
se elige \textit{{gap condition}} (ocultarlo antes de la aparición del estímulo
lateral) u \textit{{overlap condition}} (mostrarlo durante toda la duración de
la tarea) \cite{{munoz_2004_look_away}}, b) el tiempo intratrial (para la
\textit{{gap condition}}, el tiempo entre la desaparición del estímulo de
fijación y la aparición del estímulo lateral) \cite{{munoz_2004_look_away}} o
c) el tiempo asignado al \textit{{foreperiod}} (tiempo entre repeticiones)
\cite{{unsworth_2011_distribution_analysis}}.
Un diseño adecuado de la tarea facilitaría que en sus resultados se expresen
los procesos cognitivos deseados.

Además de tasas de error y tiempos de respuesta, pueden calcularse y reportarse
otra métricas relevantes a la pregunta planteada.
Por ejemplo, pueden extraerse métricas respecto de la precisión espacial
\cite{{olincy_1997_age_diminishes_performance}} o de la velocidad de las
sacadas realizadas \cite{{plomecka_2020_retest_reliability}}.
Trabajos más generales buscan establecer valores normales para gran cantidad de
variables en sujetos neurotípicos \cite{{smyrnis_2002_big_sample}}, lo cual no
sería una tarea evidente pues algunos de los valores obtenidos para sujetos
neurotípicos coinciden con resultados de sujetos esquizofrénicos reportados en
otros trabajos.
Además de estudiar el promedio de los tiempos de respuesta obtenidos, puede
estudiarse su distribución utilizando ajuste de funciones
\cite{{unsworth_2011_distribution_analysis}}.
Manipulaciones experimentales permiten luego aislar características de estas
distribuciones (e.g., desplazamientos o estiramientos).

Para múltiples condiciones neuropsicológicas se ha estudiado la correlación
entre quienes han sido diagnosticados con tales condiciones y sus resultados en
la tarea de antisacadas.
Entre estas condiciones se incluyen distintos tipos de lesiones cerebrales,
esquizofrenia, ADHD, síndrome de Parkinson, síndrome de Tourette
\cite{{munoz_2004_look_away}}, individuos sanos con baja \textit{{working
memory capacity}} \cite{{unsworth_2011_distribution_analysis}}, efectos de la
edad \cite{{olincy_1997_age_diminishes_performance,
plomecka_2020_retest_reliability}}, enfermedad de Huntington y demencia senil
\cite{{smyrnis_2002_big_sample}}, entre otros.
La tarea muestra además \textit{{test retest reliability}} (i.e., sus
resultados para mismos individuos son consistentes a lo largo de distintas
instancias de análisis clínicos) \cite{{plomecka_2020_retest_reliability}}. 

\begin{{table}}[htb]
\centering
\tiny
\begin{{tabular}}{{|p{{0.2\linewidth}}|p{{0.4\linewidth}}|p{{0.4\linewidth}}|}}
    \hline
    trabajo
    & diseño de la tarea
    & resultados generales obtenidos
    \\ \hline \hline
    Munoz et al \cite{{munoz_2004_look_away}}, analizan patrones de actividad
    neuronal en monos
    & Se intercalan sacadas y antisacadas, distinguiendo ambas tareas según el
    color del estímulo de fijación.
    Prueban \textit{{gap condition}} y \textit{{overlap condition}}.
    & Estudian patrones de activación neuronal a lo largo de las distintas
    fases de la tarea.
    Comparan sus resultados contra resultados existentes de experimentación no
    invasiva en humanos.
    Destacan como puede identificarse un primer pico de tiempos de respuesta
    correspondientes al \textit{{visual grasp reflex}}.
    Reportan además como la \textit{{overlap condition}} ayudaría a no olvidar
    el objetivo.
    \\ \hline
    Unsworth et al \cite{{unsworth_2011_distribution_analysis}}, busca aislar
    procesos cognitivos en sujetos de entre 22 y 50 años utilizando un
    mecanismo de ajuste de funciones.
    & Los sujetos se dividen mitad y mitad entre antisacada y prosacada.
    El estímulo visual es un flash rápido de una letra y en lugar de utilizar
    \eyetracking preguntan luego qué letra apareció.
    Realizan tres fases de experimentación en las cuales juegan con el tiempo
    de fijación y el tiempo de \textit{{foreperiod}} (tiempo entre
    repeticiones).
    Reciben primero 250 repeticiones, luego 350 y finalmente 3500 divididas en
    4 días.
    & Buscan aislar \textit{{goal maintenance}} y \textit{{competition
    resolution}}, para lo cual realizan ajuste de funciones, estudiando luego
    desviaciones y estiramientos de la distribución en función de las distintas
    variables experimentales.
    Además, para las prosacadas obtienen una precisión de 0.92 (0.01) y tiempo
    de respuesta (RT) de 545 ms (26 ms) y para antisacadas 0.62 (0.03) y 734 ms
    (28 ms).
    Si aleatorizan el \textit{{foreperiod}} obtienen resultados constantes para
    la prosacada pero precisión creciente en [$\sim$0.63, $\sim$0.7] y RT
    decreciente en [$\sim$800 ms, $\sim$680 ms] al ir de 200 ms a 1400 ms de
    \textit{{foreperiod}}.
    Luego de las 3500 repeticiones divididas en 4 días y 14 bloques obtienen
    \textit{{performance}} indistinguible entre ambas tareas.
    \\ \hline
    Olincy et al \cite{{olincy_1997_age_diminishes_performance}}, estudian
    impacto de la edad 42 sujetos de entre 19 y 79 años, destacándose el
    estudio de la memoria espacial 
    & Realizan una tarea visual guiada en la cual deben seguir un estímulo que
    se mueve 5°, 10° o 15° cada unos instantes y luego una tarea de antisacadas
    consistente en 1925 ms de fijación, 75 ms de pantalla en blanco, 100 ms de
    un estímulo lateral (entre 5° y 15°), 700 ms de pantalla en blanco y un
    punto final donde se supone que estén mirando
    & Además de RT y tasa de error, reportan el porcentaje de error espacial.
    Reportan RTs de $\sim$280 ms con tasas de error de $\sim$0.06 para los
    sujetos de 20 años y $\sim$580 ms con tasas de error de $\sim$0.6 para
    aquellos de 80 años.
    El error espacial no estaría correlacionado a la edad.
    \\ \hline
    Smyrnis et al \cite{{smyrnis_2002_big_sample}}, estudio sobre >2000 hombres
    de entre 18 y 25 años
    & Realizan múltiples estudios entres los cuales está la tarea de
    antisacadas.
    Su diseño consiste en un estímulo de fijación durante entre 1 s a 2 s, sin
    tiempo en blanco intermedio y con un estímulo lateral a entre 2° y 10°.
    & Buscando definir una base de valores para sujetos neurotípicos, calculan
    9 variables distintas entre las cuales están los tiempos de respuesta y las
    tasas de error.
    Los resultados son sin embargo conflictivos en que las tasas de error que
    reportan son similares a tasas de error que otros trabajos obtienen para
    pacientes esquizofrénicos.
    \\ \hline
    P{{\l}}omecka et al \cite{{plomecka_2020_retest_reliability}}, estudio del
    efecto de la edad en el control inhibitorio, realizado sobre dos grupos
    etarios (20-35 años y 60-80 años)
    & Su protocolo sigue el \textit{{internationally standardised antisaccade
    protocol}} \cite{{antoniades_2013_standarized_protocol}} que indica 2
    bloques de 60 prosacadas y 3 bloques de 40 antisacadas.
    Los estímulos se presentan a 10° del centro.
    & Además de \textit{{saccadic gain}} y velocidades pico, para la primera
    instancia de reportan:
    \begin{{itemize}}
        \item grupo joven, prosacada: RT promedio de 268 ms (sd 83 ms), taza de
        error de 1.3\% (sd 1.92\%)
        \item grupo joven, antisacada: RT promedio de 303 ms (sd 88 ms), taza
        de error de 7.83\% (sd 6.54\%)
        \item grupo mayor, prosacada: RT promedio de 309 ms (sd 118 ms), taza
        de error de 5.35\% (sd 5.31\%)
        \item grupo mayor, antisacada: RT promedio de 360 ms (sd 130 ms), taza
        de error de 17.2\% (sd 14.7\%)
    \end{{itemize}}
    Obtienen luego \textit{{good reliability}} y \textit{{excellent
    reliability}}, según la interpretación [Cicchetti, 1994] de los
    coeficientes de correlación intraclase (ICC).
    Realizan dos instancias de experimentación para poder estudiar
    \textit{{test retest reliability}} para entender luego el potencial de la
    tarea de antisacadas como marcador clínico de deterioro cognitivo.
    \\ \hline
\end{{tabular}}
La tarea puede ser utilizada para distintos fines.
Decisiones de diseño (tiempos de las distintas etapas, cómo se muestran los
estímulos visuales) impactan en qué procesos cognitivos se expresan con mayor
magnitud.

TODO: Comentario similar para esta tabla, capaz más que una tabla conviene
ponerlo en una lista

\caption{{Distintos usos de la tarea de antisacadas}}
\label{{tab:antisaccades}}
\end{{table}}


TODO: Cuando esté más cocinado metodo habría que ver como cerrar la intro para
      que conecten bien
